{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten Digit Recognition using kNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "98c17213-ead9-401b-ab44-7ac757463452"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhCQhICpnDAc"
      },
      "source": [
        "### Downloading MNIST Train and Test Datasets  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af2b3cb8-8391-471c-9271-03ad0901be20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5297183-087f-49b8-9946-e0dc185b26c9"
      },
      "source": [
        "# Downloading the datasets using wget\n",
        "!wget https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/mnist_train.csv\n",
        "!wget https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/mnist_test.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-15 17:16:48--  https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/mnist_train.csv\n",
            "Resolving nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com (nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com)... 52.219.160.70\n",
            "Connecting to nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com (nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com)|52.219.160.70|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 109575994 (104M) [text/csv]\n",
            "Saving to: ‘mnist_train.csv’\n",
            "\n",
            "mnist_train.csv     100%[===================>] 104.50M  13.1MB/s    in 10s     \n",
            "\n",
            "2021-09-15 17:16:59 (10.5 MB/s) - ‘mnist_train.csv’ saved [109575994/109575994]\n",
            "\n",
            "--2021-09-15 17:16:59--  https://nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com/otg_prod/media/Tech_4.0/AI_ML/Datasets/mnist_test.csv\n",
            "Resolving nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com (nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com)... 52.219.64.127\n",
            "Connecting to nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com (nkb-backend-otg-media-static.s3.ap-south-1.amazonaws.com)|52.219.64.127|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18289443 (17M) [text/csv]\n",
            "Saving to: ‘mnist_test.csv’\n",
            "\n",
            "mnist_test.csv      100%[===================>]  17.44M  5.69MB/s    in 3.1s    \n",
            "\n",
            "2021-09-15 17:17:03 (5.69 MB/s) - ‘mnist_test.csv’ saved [18289443/18289443]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "328c3961-828b-49c4-84de-9421c795ef93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7f4859c-63a1-44a6-eb2c-baf74010129d"
      },
      "source": [
        "# Checking the last few lines of the downloaded files\n",
        "!tail mnist_train.csv\n",
        "!tail mnist_test.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,107,229,255,254,26,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,157,242,253,253,165,227,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,130,244,253,184,54,10,1,7,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,24,179,253,181,67,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,208,181,99,4,0,0,0,0,4,27,120,200,118,0,0,0,0,0,0,0,0,0,0,0,0,0,0,234,253,73,0,0,0,0,12,73,137,253,253,253,79,0,0,0,0,0,0,0,0,0,0,0,0,0,123,251,151,20,16,61,141,223,226,238,253,253,237,64,5,0,0,0,0,0,0,0,0,0,0,0,0,0,99,249,253,253,253,252,191,150,74,22,242,253,104,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,91,144,53,41,40,0,0,21,202,253,100,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,212,253,95,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,243,253,101,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,170,237,135,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,188,253,113,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,115,251,149,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,86,229,218,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,117,240,189,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,116,229,173,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,88,243,216,74,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,45,226,248,103,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,226,142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,24,24,24,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,162,204,254,253,253,136,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,143,235,253,253,216,184,235,253,75,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,87,253,253,177,109,21,0,91,253,170,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,137,54,4,0,0,0,38,233,190,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,254,76,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,216,211,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,143,235,154,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,212,154,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,106,244,232,38,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,234,243,42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,175,253,136,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,70,70,57,0,0,0,0,13,172,228,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,100,225,253,254,245,208,114,93,104,216,228,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,148,247,253,200,138,212,253,253,253,254,253,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,98,254,206,116,11,3,119,254,254,254,245,254,223,44,24,0,0,0,0,0,0,0,0,0,0,0,0,0,254,224,25,0,43,119,253,253,215,102,51,92,176,207,207,0,0,0,0,0,0,0,0,0,0,0,0,0,255,241,153,164,247,255,209,100,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,170,253,253,253,117,46,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,23,23,23,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,70,161,249,213,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,109,193,231,253,217,224,254,169,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,27,191,247,186,136,54,0,48,254,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,217,179,22,0,0,0,0,48,207,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,36,243,152,17,0,0,0,0,0,13,100,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,114,254,27,10,0,12,19,19,48,175,254,169,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,254,254,218,180,228,254,251,195,254,248,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,76,104,104,104,104,19,9,132,254,158,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,54,242,168,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,50,195,226,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,18,200,225,32,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,200,221,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,171,253,83,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,166,254,127,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,162,254,149,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,145,253,182,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,118,254,235,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,103,253,235,49,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,111,238,217,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,170,219,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,98,128,128,192,207,132,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,74,178,223,250,234,191,155,111,41,32,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,20,129,250,194,134,25,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,226,164,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,18,32,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,135,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,36,228,246,47,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,223,254,224,134,120,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,100,159,159,159,174,239,174,116,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,40,173,238,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,82,0,0,0,0,0,0,0,0,0,151,200,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,136,73,0,0,0,0,0,0,0,0,0,57,239,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,239,20,0,0,0,0,0,0,0,0,0,131,239,22,0,0,0,0,0,0,0,0,0,0,0,0,0,0,225,185,81,16,16,16,16,16,61,145,229,194,40,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,99,206,254,254,254,255,254,248,222,172,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,48,92,127,73,48,39,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,230,83,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,158,244,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,55,245,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,254,196,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,76,250,194,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,150,254,162,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,99,255,160,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,105,251,194,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,59,248,197,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,221,243,41,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,251,142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,190,245,102,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,63,254,155,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,223,254,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,230,175,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,185,242,56,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,241,110,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,129,235,30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,201,231,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,170,171,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,67,146,216,255,254,255,255,139,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,68,237,253,205,177,177,177,239,253,208,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,200,253,50,12,0,0,0,26,196,253,137,114,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,253,253,21,0,0,0,0,0,135,253,253,248,63,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,222,253,21,0,0,0,0,0,170,253,253,106,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,107,253,72,0,0,1,37,207,252,218,45,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,49,253,199,18,18,113,253,253,169,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,171,253,146,147,253,253,183,32,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,188,253,253,245,140,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,92,246,253,253,55,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,124,253,253,253,253,55,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,141,253,253,128,62,240,236,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,195,253,242,111,7,0,138,239,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,47,234,253,203,39,0,0,0,93,249,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,221,253,233,28,0,0,0,0,53,247,132,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,253,242,48,0,0,0,0,0,93,248,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,251,79,0,0,0,0,0,0,136,232,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,248,0,0,0,7,33,40,210,241,156,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,76,252,160,106,179,193,253,253,208,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,147,253,253,202,145,145,93,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,129,253,192,109,109,109,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,115,252,252,253,252,252,252,156,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,63,216,252,252,253,252,252,252,253,66,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,108,108,170,128,211,252,253,252,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,252,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,125,253,210,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,47,221,253,252,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,145,144,221,252,253,210,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,171,253,253,253,255,253,253,253,84,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,253,252,252,252,253,252,220,35,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,215,215,215,253,252,215,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,148,236,144,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,218,253,170,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,93,252,210,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,120,104,0,0,0,0,0,0,0,0,94,252,190,0,0,0,0,0,0,0,0,0,0,0,0,0,42,160,252,143,0,0,0,0,0,0,0,0,217,231,46,0,0,0,0,0,0,0,0,0,0,0,0,0,218,253,253,191,15,0,0,0,0,0,0,47,233,217,0,0,0,0,0,0,0,0,0,0,0,0,0,0,175,252,252,252,222,217,217,135,175,94,217,233,252,91,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,175,215,252,252,252,252,253,252,252,252,253,179,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,108,108,108,190,108,232,252,168,108,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,96,121,213,255,255,121,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,52,108,157,241,251,253,253,242,146,69,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,94,164,241,253,253,223,159,131,26,23,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,60,102,218,253,253,216,117,39,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,54,205,253,253,253,147,28,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,60,240,253,253,253,243,31,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,80,208,253,253,147,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,36,222,253,253,121,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,177,242,253,248,147,148,91,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,120,197,253,254,253,97,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,72,192,254,254,40,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,242,253,39,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,121,253,159,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,253,173,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,253,173,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,253,74,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,0,0,0,0,0,0,0,0,0,20,201,253,39,0,0,0,0,0,0,0,0,0,0,0,0,0,0,196,161,41,5,0,0,0,3,27,98,206,253,194,15,0,0,0,0,0,0,0,0,0,0,0,0,0,0,115,240,252,163,147,147,147,158,253,253,255,184,67,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,157,253,253,253,253,253,253,253,121,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,55,192,230,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,152,252,193,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,129,252,190,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,155,252,210,14,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,62,216,199,66,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,43,254,222,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,143,252,222,16,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,169,246,208,17,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,143,246,236,101,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,69,226,199,111,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,254,253,21,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,124,253,110,5,0,0,0,0,0,22,128,191,190,137,28,0,0,0,0,0,0,0,0,0,0,0,0,112,241,170,32,0,0,0,31,127,180,237,252,253,252,242,42,0,0,0,0,0,0,0,0,0,0,0,6,190,226,0,0,0,0,27,218,252,194,162,84,84,131,232,35,0,0,0,0,0,0,0,0,0,0,0,110,252,147,0,0,0,0,194,253,217,56,0,0,18,216,187,0,0,0,0,0,0,0,0,0,0,0,0,233,216,18,0,0,0,27,194,150,106,9,0,124,255,186,9,0,0,0,0,0,0,0,0,0,0,0,64,247,110,0,0,0,0,0,0,0,0,87,146,163,63,16,0,0,0,0,0,0,0,0,0,0,0,0,14,236,128,0,0,0,11,22,66,128,206,231,178,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,28,239,196,169,82,169,211,252,252,128,84,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,36,241,252,252,253,217,138,42,42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,48,48,22,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,62,97,198,243,254,254,212,27,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,67,172,254,254,225,218,218,237,248,40,0,21,164,187,0,0,0,0,0,0,0,0,0,0,0,0,0,89,219,254,97,67,14,0,0,92,231,122,23,203,236,59,0,0,0,0,0,0,0,0,0,0,0,0,25,217,242,92,4,0,0,0,0,4,147,253,240,232,92,0,0,0,0,0,0,0,0,0,0,0,0,0,101,255,92,0,0,0,0,0,0,105,254,254,177,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,167,244,41,0,0,0,7,76,199,238,239,94,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,192,121,0,0,2,63,180,254,233,126,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,190,196,14,2,97,254,252,146,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,130,225,71,180,232,181,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,130,254,254,230,46,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,77,244,254,162,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,110,254,218,254,116,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,131,254,154,28,213,86,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,209,153,19,19,233,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,142,254,165,0,14,216,167,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,90,254,175,0,18,229,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,26,229,249,176,222,244,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,73,193,197,134,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,29,125,147,255,255,241,51,0,0,0,0,0,0,0,0,0,0,0,0,0,0,49,12,104,118,118,222,248,249,253,253,253,253,253,231,0,0,0,0,0,0,0,0,0,0,0,0,0,0,229,243,252,253,253,253,253,253,253,253,253,253,253,176,0,0,0,0,0,0,0,0,0,0,0,0,0,0,181,253,253,253,253,253,253,253,178,167,253,253,253,104,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,25,139,112,25,25,25,25,7,46,253,253,253,104,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,93,253,253,253,104,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,176,253,253,244,69,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,240,253,253,227,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,156,253,253,253,190,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,201,253,253,245,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,90,253,253,253,124,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,202,253,253,245,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,253,253,245,109,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,12,205,253,253,207,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,253,253,253,207,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,202,253,253,253,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,206,253,253,249,72,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,253,253,253,194,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,253,253,253,71,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,227,253,223,35,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,191,255,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,255,0,64,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,255,255,255,255,255,255,255,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,255,255,255,191,0,191,255,255,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,255,128,255,255,255,255,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,255,255,255,255,255,128,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,255,0,128,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,64,0,64,191,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,128,0,0,0,64,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,0,0,0,0,0,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,64,0,0,0,0,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,191,128,191,128,191,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,255,255,255,255,255,255,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,255,255,255,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,191,255,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,89,156,231,255,163,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,35,165,253,253,253,254,253,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,43,153,224,253,253,180,174,254,253,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,70,237,253,207,71,19,2,0,254,253,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,147,253,253,177,23,0,0,0,0,254,253,78,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,217,254,254,131,0,0,0,0,0,83,255,254,101,0,0,0,0,0,0,0,0,0,0,0,0,0,87,229,254,251,135,3,0,0,0,44,132,244,254,253,129,0,0,0,0,0,0,0,0,0,0,0,0,85,247,253,235,124,0,0,0,0,112,229,253,253,254,253,78,0,0,0,0,0,0,0,0,0,0,0,0,175,253,253,120,0,0,52,212,235,250,253,253,253,254,167,6,0,0,0,0,0,0,0,0,0,0,0,16,235,253,253,240,195,195,248,253,254,253,253,253,253,231,24,0,0,0,0,0,0,0,0,0,0,0,0,20,254,254,254,255,254,254,222,120,38,5,156,254,254,38,0,0,0,0,0,0,0,0,0,0,0,0,0,3,136,233,241,241,225,135,25,0,0,103,253,253,207,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,30,30,0,0,0,0,19,196,253,240,70,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,112,253,253,146,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,231,253,222,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,158,255,254,152,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,199,254,236,42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,70,253,254,135,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,227,253,207,25,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,159,253,60,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,110,109,109,47,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,176,217,253,252,252,232,218,93,21,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,37,182,201,252,252,253,252,252,252,253,252,92,0,0,0,0,0,0,0,0,0,0,0,0,0,1,42,160,252,253,252,252,252,253,252,252,252,253,252,215,1,0,0,0,0,0,0,0,0,0,0,0,63,170,252,252,252,253,252,252,252,253,252,252,252,253,252,252,108,0,0,0,0,0,0,0,0,0,0,73,237,252,252,252,252,253,252,252,252,253,231,179,221,253,252,252,232,0,0,0,0,0,0,0,0,0,53,232,252,252,252,252,252,253,252,252,252,237,71,0,125,253,252,252,252,0,0,0,0,0,0,0,0,0,73,252,252,252,252,252,252,253,252,252,252,62,0,0,0,253,252,252,168,0,0,0,0,0,0,0,0,0,42,222,253,253,253,253,253,255,222,125,0,0,0,0,63,255,253,237,62,0,0,0,0,0,0,0,0,0,21,201,252,252,252,252,252,253,55,0,0,0,0,0,144,253,252,215,0,0,0,0,0,0,0,0,0,0,73,252,252,252,252,252,252,253,190,72,0,0,0,6,160,253,252,195,0,0,0,0,0,0,0,0,0,0,155,252,252,252,252,252,252,253,252,236,62,0,0,120,252,253,210,31,0,0,0,0,0,0,0,0,0,171,253,253,253,253,159,41,0,0,0,0,0,110,150,253,253,255,119,0,0,0,0,0,0,0,0,0,0,253,252,252,252,252,35,0,0,0,0,11,73,253,252,252,252,222,25,0,0,0,0,0,0,0,0,0,0,253,252,252,252,252,190,181,181,99,181,191,252,253,252,252,231,41,0,0,0,0,0,0,0,0,0,0,0,253,252,252,252,252,252,252,252,253,252,252,252,253,252,231,46,0,0,0,0,0,0,0,0,0,0,0,0,192,253,253,253,253,253,253,253,255,253,253,253,255,119,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,180,252,252,252,252,252,252,253,252,200,179,35,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,21,71,71,71,195,195,71,72,71,20,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,255,109,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,199,253,253,37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,39,229,253,247,34,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,141,253,253,94,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,192,253,253,104,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,192,253,253,43,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,233,253,253,43,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,87,253,253,253,43,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,186,253,253,196,13,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,42,235,253,253,172,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,56,253,253,253,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,153,253,253,195,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,41,239,253,253,179,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,153,253,253,253,136,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,203,253,253,253,55,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,153,253,253,253,144,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,203,253,253,253,61,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,253,253,253,226,35,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,253,253,253,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,109,253,137,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,191,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,64,255,255,255,255,255,255,255,128,128,255,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,255,191,128,0,0,0,64,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,128,0,0,0,0,0,0,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,128,0,0,0,0,0,0,0,64,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,191,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,191,128,128,128,128,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,255,255,255,255,255,255,128,0,0,0,0,0,0,0,0,0,0,0,191,255,255,255,255,255,255,255,255,128,128,128,128,191,255,255,128,0,0,0,0,0,0,0,0,0,0,0,255,255,255,255,255,255,128,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,255,255,128,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,118,242,218,96,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,98,178,254,254,254,251,220,42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,163,220,254,254,254,254,254,254,254,150,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,58,240,254,254,254,254,254,254,254,254,249,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,66,246,254,254,237,160,130,229,254,254,254,130,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,183,222,103,50,0,0,77,254,254,250,53,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,207,254,254,251,68,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,253,254,254,254,252,73,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,10,212,254,254,254,254,244,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,77,185,230,254,254,254,239,45,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,60,207,254,254,254,81,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,254,254,254,199,9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,254,254,254,254,75,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,7,254,254,254,254,75,0,0,0,0,0,0,0,0,0,0,0,0,0,80,90,0,0,0,0,0,0,0,7,254,254,254,254,75,0,0,0,0,0,0,0,0,0,0,0,0,186,247,250,134,0,0,0,0,0,70,222,254,254,254,155,10,0,0,0,0,0,0,0,0,0,0,0,0,214,254,254,252,129,63,63,101,200,236,254,254,254,234,41,0,0,0,0,0,0,0,0,0,0,0,0,0,64,211,254,254,254,254,254,254,254,254,254,254,238,69,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,73,192,254,254,254,254,254,254,254,254,234,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,117,187,254,254,254,254,164,114,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,23,217,228,35,0,0,0,0,113,241,146,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,116,254,218,32,0,0,0,54,238,254,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,108,254,254,74,0,0,0,46,236,254,198,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,216,254,250,67,0,0,0,154,254,254,142,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,4,168,254,254,189,0,0,0,62,236,254,254,30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,254,254,248,69,0,0,11,208,254,254,176,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,47,254,254,211,0,0,11,101,254,254,254,37,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,149,254,254,241,174,174,194,254,254,254,254,80,6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,123,254,254,254,254,254,254,254,254,254,254,254,30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,230,254,254,254,254,254,254,254,254,254,254,30,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,80,186,199,254,254,254,254,199,186,80,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,50,254,254,254,196,11,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,176,254,254,254,79,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,254,254,254,197,10,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,14,182,254,254,254,80,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,254,254,254,199,8,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,150,254,254,254,140,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,162,254,254,230,38,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,162,254,254,140,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,102,255,230,38,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,10,78,0,0,0,0,0,0,0,15,104,104,104,69,0,0,0,0,0,0,0,0,0,0,0,0,123,238,254,235,159,76,111,76,115,169,169,238,254,254,254,254,0,0,0,0,0,0,0,0,0,0,0,71,252,254,254,254,254,254,254,254,254,254,254,254,254,254,248,102,0,0,0,0,0,0,0,0,0,0,0,83,254,254,254,254,254,247,236,221,179,235,182,140,110,47,42,0,0,0,0,0,0,0,0,0,0,0,39,229,254,254,194,169,124,47,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,254,254,254,248,133,51,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,5,213,254,254,254,254,249,91,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,152,201,254,254,254,135,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,25,237,106,0,0,0,32,200,254,255,50,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,123,251,181,0,0,0,13,156,254,254,126,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,254,254,56,0,0,0,85,254,254,254,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,198,254,149,54,0,0,60,251,254,254,29,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,89,248,254,220,107,148,236,253,248,171,7,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,139,249,254,254,254,254,249,173,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,97,194,254,254,254,134,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,97,103,37,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n",
            "6,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,8,117,254,220,89,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,95,212,253,253,253,157,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,16,95,209,253,253,253,245,125,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,40,96,206,253,254,253,253,198,64,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,182,240,253,253,253,254,253,198,24,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,15,60,60,168,253,253,254,200,23,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,70,247,253,253,245,21,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,75,207,253,253,207,92,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,219,253,253,253,138,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,105,250,253,253,253,34,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,95,254,254,254,254,94,0,0,0,0,0,3,13,13,13,8,0,0,0,0,0,0,0,0,0,0,0,0,107,253,253,253,204,15,0,0,0,0,21,166,253,253,253,212,25,0,0,0,0,0,0,0,0,0,0,33,217,253,253,132,64,0,0,18,43,157,171,253,253,253,253,253,160,2,0,0,0,0,0,0,0,0,3,166,253,253,242,49,17,49,158,210,254,253,253,253,253,253,253,253,253,11,0,0,0,0,0,0,0,0,10,227,253,253,207,15,172,253,253,253,254,247,201,253,210,210,253,253,175,4,0,0,0,0,0,0,0,0,10,228,253,253,224,87,242,253,253,184,60,54,9,60,35,182,253,253,52,0,0,0,0,0,0,0,0,0,13,253,253,253,253,231,253,253,253,93,86,86,86,109,217,253,253,134,5,0,0,0,0,0,0,0,0,0,2,115,253,253,253,253,253,253,253,253,254,253,253,253,253,253,134,5,0,0,0,0,0,0,0,0,0,0,0,3,166,253,253,253,253,253,253,253,254,253,253,253,175,52,5,0,0,0,0,0,0,0,0,0,0,0,0,0,7,35,132,225,253,253,253,195,132,132,132,110,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47d30efd-945e-4302-a9c2-670178356231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b5b6642-98ba-4cd2-aeab-8024dc04e8b5"
      },
      "source": [
        "file_name = \"mnist_train.csv\"\n",
        "data = np.genfromtxt(file_name, delimiter=',', dtype=np.int)\n",
        "print(f\"Shape of the data in {file_name} is: {data.shape} \\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the data in mnist_train.csv is: (60000, 785) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dcc216c-2afc-49fd-aad0-a6f78e995a6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e83766c-d196-470c-837d-923b16a3188f"
      },
      "source": [
        "MNIST_Y = data[:, 0].reshape(-1, 1)\n",
        "MNIST_X = data[:, 1:]\n",
        "\n",
        "print(f\"Shape of X: {MNIST_X.shape} \\n\")\n",
        "print(f\"Shape of Y: {MNIST_Y.shape} \\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: (60000, 784) \n",
            "\n",
            "Shape of Y: (60000, 1) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffe9411d-c223-4146-942d-769db0f799c7"
      },
      "source": [
        "### 1. Ln Norm Distances between two Arrays\n",
        "\n",
        "Implementing the **`Ln_norm_distances()`** function which computes the distance between a testing instance and each of the training instances.\n",
        "\n",
        "\n",
        "**Arguments**:\n",
        "* **`train_X`** : Inputs from training data\n",
        "  * A 2D numpy array of floats where each row represents the input of a training instance\n",
        "\n",
        "* **`test_x`** : Testing Input\n",
        "  * A 1D numpy array of floats \n",
        "\n",
        "* **`n`** \n",
        "  * `n` in the Ln-Norm Distance (>= 1)\n",
        "\n",
        "**Returns**: \n",
        "* Array of distances between testing instance and each of the training instances.\n",
        "  * A 1D numpy array of floats\n",
        "\n",
        "**Numpy methods used**:\n",
        "* **`np.abs`**, **`np.sum`** and **`np.power`**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2775424-f465-4072-974a-ed9465f0e42f"
      },
      "source": [
        "def Ln_norm_distances(train_X, test_x, n):\n",
        "    abs_diff = np.abs(train_X - test_x)  \n",
        "    summation = np.sum(np.power(abs_diff, n), axis=1)\n",
        "    ln_distances = np.power(summation, 1/n)\n",
        "    return ln_distances\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c7133b7-fea1-44dc-abcb-1e8df98454f7"
      },
      "source": [
        "### 2. k-nearest Neighbours\n",
        "\n",
        "Implementing the `k_nearest_neighbours()` function which computes the k nearest neighbours of a testing instance.\n",
        "\n",
        "\n",
        "**Arguments**:\n",
        "* **`train_X`** : Inputs from training data\n",
        "  * A 2D numpy array of floats where each row represents the input of a training instance\n",
        "\n",
        "* **`test_x`** : Testing Input\n",
        "  * A 1D numpy array of floats\n",
        "\n",
        "* **`n`** \n",
        "  * `n` in Ln-Norm Distance (>=1)\n",
        "\n",
        "* **`k`** \n",
        "  * The number of nearest neighbours to consider. \n",
        "  * 1 $\\le$ **k** $\\le$ number of training instances\n",
        "\n",
        "**Returns**:\n",
        "* Indices of k-nearest neighbours to **`test_x`**.\n",
        " * A 1D numpy array of `ints`\n",
        "* Distances of the corresponding k-nearest neighbors from **`test_x`**.\n",
        " * A 1D numpy array of `floats`\n",
        "\n",
        "**NOTE:**   \n",
        "In case of a distance tie, breaking the tie by considering all the points equidistant from **`test_x`**. That is, return all the points which are equidistant from **`test_x`**.\n",
        "\n",
        "\n",
        "**Methods used**: \n",
        "* Calling **`Ln_norm_distances`** method implemented in the previous question.\n",
        "* **`np.argsort`** method is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "724bbc19-54e5-44f6-93f6-3d32d396dc56"
      },
      "source": [
        "def k_nearest_neighbours(train_X, test_x, n, k):\n",
        "  distances = Ln_norm_distances(train_X, test_x, n)\n",
        "  indices = np.argsort(distances)\n",
        "  k_repeat_count = 0\n",
        "  if int(distances.shape[0]) > k:\n",
        "    Kth_nn_index = indices[k-1] \n",
        "    kth_nn_distance = distances[Kth_nn_index]\n",
        "    indices_except_top_k = indices[k:]\n",
        "    distances_except_top_k = distances[indices_except_top_k]\n",
        "    k_repeat_count = np.count_nonzero(distances_except_top_k == kth_nn_distance)\n",
        "  \n",
        "  top_indices = indices[:(k + k_repeat_count)]\n",
        "  top_distances = distances[top_indices]\n",
        "\n",
        "  return top_indices, top_distances\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de526afc-6b0e-436a-8f1e-bda7d63b6379"
      },
      "source": [
        "### 3. Distance weighted k-NN\n",
        "Implementing the `distance_weighted_knn()` function which predicts the class label for testing instances based on the *'Distance Weighted k-NN'* algorithm discussed in the sessions.\n",
        "\n",
        "\n",
        "**Arguments**:\n",
        "* **`train_X`** : Inputs from training data.\n",
        "  * A 2D numpy array of `floats` where each row represents the input of a training instance\n",
        "\n",
        "* **`train_Y`** : Outputs from training data (target labels).\n",
        "  * A 1D numpy array of `ints`\n",
        "\n",
        "* **`test_X`** : Inputs from testing data for which the class labels have to be predicted.\n",
        "  * A 2D numpy array of `floats` where each row represents the input of a testing instance\n",
        "\n",
        "\n",
        "* **`n`** \n",
        "  * `n` in Ln-Norm Distance (>=1)\n",
        "\n",
        "* **`k`** \n",
        "  * The number of nearest neighbours to consider.\n",
        "  * 1 $\\le$ **k** $\\le$ number of training instances.\n",
        "\n",
        "**Returns**:\n",
        "* Predicted labels for `test_X` \n",
        " * A 1D numpy array of ints where $i^{th}$ element is the predicted label for $i^{th}$ element in **`test_X`**\n",
        "\n",
        "**NOTE:**  \n",
        "In case of a tie among the weighted votes, breaking the tie randomly. That is, choose one of the labels which are tied.\n",
        "\n",
        "**Methods used**: \n",
        "* Calling **`k_nearest_neighbours`** and **`distance_weighted_voting`** methods.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2742fa27-1d1d-4f9f-a6b3-ef4873b84d64"
      },
      "source": [
        "def distance_weighted_knn(train_X, train_Y, test_X, n, k):\n",
        "    unique_class_labels = np.unique(train_Y)\n",
        "    l = int(test_X.shape[0])\n",
        "    m = int(unique_class_labels.shape[0])\n",
        "    weights_array = np.zeros((l,m))\n",
        "    for test_id, test_input in enumerate(test_X):\n",
        "      top_indices, top_distances = k_nearest_neighbours(train_X, test_input, n, k)\n",
        "      top_labels = train_Y[top_indices]\n",
        "      for label_id, each_label in enumerate(unique_class_labels):\n",
        "        label_weight = np.sum(np.where(top_labels == each_label, 1/top_distances,0))\n",
        "        weights_array[test_id][label_id] = label_weight\n",
        "      \n",
        "    highest_weight_indices = np.argmax(weights_array,axis=1)\n",
        "    predicted_test_Y = unique_class_labels[highest_weight_indices]\n",
        "    return predicted_test_Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad862aad-691b-435e-81ee-bbfa61ce340a"
      },
      "source": [
        "### 4. Majority based k-NN\n",
        "Implementing the `majority_based_knn()` function which predicts the class label for testing instances based on the majority label among k-nearest neighbors.\n",
        "\n",
        "**Arguments**:\n",
        "* **`train_X`** : Inputs from training data.\n",
        "  * A 2D numpy array of floats where each row represents the input of a training instance\n",
        "\n",
        "* **`train_Y`** : Outputs from training data (target labels).\n",
        "  * A 1D numpy array of ints\n",
        "\n",
        "* **`test_X`** : Inputs from testing data for which the class labels have to be predicted.\n",
        "  * A 2D numpy array of floats where each row represents the input of a testing instance\n",
        "\n",
        "* **`n`** \n",
        "  * `n` in Ln-Norm Distance (>=1)\n",
        "\n",
        "* **`k`** \n",
        "  * The number of nearest neighbours to consider.\n",
        "  * 1 $\\le$ **k** $\\le$ number of training instances.\n",
        "\n",
        "**Returns**:\n",
        "* Predicted labels for `test_X` \n",
        " * A 1D numpy array of ints where $i^{th}$ element is the predicted label for $i^{th}$ element in **`test_X`**\n",
        "\n",
        "**NOTE:**  \n",
        "* In case of voting ties, breaking the ties using the distance weighted voting technique.   \n",
        "* In case if there is a tie even after considering weights, breaking it randomly.\n",
        "\n",
        "**Methods used**: \n",
        "* Making use of **`np.unique`**, **`np.argsort`**, **`np.max`**, **`np.where`** methods.\n",
        "* Calling **`k_nearest_neighbours`** and **`distance_weighted_voting`** methods implemented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50b2e6e6-800b-4242-8852-057d0e055969"
      },
      "source": [
        "def majority_based_knn(train_X, train_Y, test_X, n, k):\n",
        "    unique_class_labels = np.unique(train_Y)\n",
        "    l = int(test_X.shape[0])\n",
        "    m = int(unique_class_labels.shape[0])\n",
        "    weights_array = np.zeros((l,m))\n",
        "    counts_array = np.zeros((l,m))\n",
        "    for test_id, test_input in enumerate(test_X):\n",
        "      top_indices, top_distances = k_nearest_neighbours(train_X, test_input, n, k)\n",
        "      top_labels = train_Y[top_indices]\n",
        "      for label_id, class_label in enumerate(unique_class_labels):\n",
        "        class_count = np.sum(np.where(top_labels == class_label , 1.0, 0.0))\n",
        "        class_weight = np.sum(np.where(top_labels == class_label, 1/top_distances,0))\n",
        "        weights_array[test_id][label_id] = class_weight\n",
        "        counts_array[test_id][label_id] = class_count\n",
        "    \n",
        "    predicted_test_Y = np.empty(l,dtype=int)\n",
        "\n",
        "    sorted_count_indices = np.argsort(counts_array,axis=1)\n",
        "    for test_id,test_indices in enumerate(sorted_count_indices):\n",
        "      highest_count = counts_array[test_id][test_indices[m-1]]\n",
        "      highest_label_repeat = np.count_nonzero(counts_array[test_id] == highest_count)\n",
        "\n",
        "      no_voting_tie = (highest_label_repeat == 1)\n",
        "      if no_voting_tie:\n",
        "        predicted_test_Y[test_id] = unique_class_labels[test_indices[m-1]]\n",
        "      else:\n",
        "        tied_class_indices = test_indices[m-highest_label_repeat:]\n",
        "        tied_class_weights = weights_array[test_id][tied_class_indices]\n",
        "        max_weight_id = np.argmax(tied_class_weights)\n",
        "        max_id = tied_class_indices[max_weight_id]\n",
        "        predicted_test_Y[test_id] = unique_class_labels[max_id]\n",
        "\n",
        "    return predicted_test_Y\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69a37da6-f5fc-4b3f-8b72-4fe3b3d572c9"
      },
      "source": [
        "### 5. Accuracy of k-NN algorithm\n",
        "\n",
        "\n",
        "Implementing the **`calculate_accuracy()`** function which computes the accuracy, given the actual and the predicted labels.\n",
        "\n",
        "**Arguments**:\n",
        "* **`predicted_labels`** \n",
        "  * A 1D numpy array of ints\n",
        "\n",
        "* **`actual_labels`** \n",
        "  * A 1D numpy array of ints\n",
        "\n",
        "**Returns**:\n",
        "* A `float` value which represents the accuracy for given **`predicted_labels`** and **`actual_labels`**\n",
        "\n",
        "**Methods used**: \n",
        "* Making use of **`np.count_nonzero`** method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b65d04ea-00b8-472a-a17c-ccf7e5d7c5bd"
      },
      "source": [
        "def calculate_accuracy(predicted_labels, actual_labels):\n",
        "    # ADD YOUR CODE HERE\n",
        "    correctly_predicted_count = np.count_nonzero(predicted_labels == actual_labels)\n",
        "    accuracy = float(correctly_predicted_count)/predicted_labels.size\n",
        "    return accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_X9dHdIDX6T"
      },
      "source": [
        "### 6. Best `k` and `n` values\n",
        "\n",
        "Implementing the **`get_best_k_n_values_using_validation_set()`** function, which returns\n",
        "\n",
        "1.   the best **`'k'`** value, i.e., the number of nearest neighbors to consider and \n",
        "\n",
        "2.   the best **`'n'`** value in Ln-norm distance, i.e, the distance metric which should be used.\n",
        "\n",
        "\n",
        "**Arguments**:\n",
        "* **`train_X`** : Inputs from training data.\n",
        "  * A 2D numpy array of floats where each row represents the input of a training instance\n",
        "\n",
        "* **`train_Y`** : Outputs from training data (target labels).\n",
        "  * A 1D numpy array of `ints`\n",
        "\n",
        "* **`validation_split_percent`** : An `int` which denotes the percentage of `train_X` data that should be used as validation data.\n",
        "\n",
        "* **`possible_values_for_n`**\n",
        "  * An `ndarray` of `ints` which represents the values for **`n`** which is considered when trying to find out the best value of `n` in Ln-norm distances.\n",
        "\n",
        "**Returns**:\n",
        "* The best **`k, n`** pair which should be used in the k-NN algorithm for the given data.\n",
        "  * A 1D numpy array of `ints` where the $1^{st}$ element is the **`k`** value and the second element is the **`n`** value.\n",
        "\n",
        "**NOTE:**  \n",
        "1. Shuffling the given training data before splitting it into training set and validation set.  \n",
        "2. From the shuffled training set,\n",
        "\n",
        "> 1. The first $math.floor(\\frac{100-P}{100}*M)$ number of instances are used as the training set.  \n",
        "> 2. The remaining instances are used as the validation set.  \n",
        "\n",
        "> Here, $P$ is the `validation_split_percent` and $M$ is the number of instances in `train_X`.\n",
        "\n",
        "3. Using the **`majority_based_knn()`** function that is implemented to predict labels using k-NN.\n",
        "4. For choosing the best value for $k$, trying all possible values from 1 to number of instances in training set.<br>\n",
        "For the choosing best value for $n$, trying values mentioned in the `possible_values_for_n` array. <br> <br>\n",
        "\n",
        "5. In case of a tie (same accuracies), returns the **`(k, n)`** pair with the least value of **`'n'`**. If the **`'n'`** values of two or more such pairs are also the same, then returns **`(k, n)`** pair with the least value of **`'k'`** among such pairs. <br> <br>\n",
        "\n",
        "\n",
        "**Methods and Techniques used:**  \n",
        "* Hyperparameter tuning technique is used. That is, iteratively trying various combinations of hyperparameter values and pick the values that give the best performance.  <br><br>\n",
        "* Making use of **`np.argsort`** method.\n",
        "* Calling **`calculate_accuracy`** method implemented in the previous question."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4c394281-a995-4dc6-84b1-06119680a37f"
      },
      "source": [
        "import math\n",
        "def shuffle(X, Y):\n",
        "  np.random.seed(2)\n",
        "  indices = np.random.permutation(X.shape[0])\n",
        "  shuffled_X = X[indices]\n",
        "  shuffled_Y = Y[indices]\n",
        "  return shuffled_X, shuffled_Y\n",
        "\n",
        "def get_best_k_n_values_using_validation_set(train_X, train_Y, validation_split_percent,possible_values_for_n):\n",
        "    inputs, labels = shuffle(train_X, train_Y)\n",
        "    train_length = math.floor(((float(100 - validation_split_percent))/100) * train_X.shape[0])\n",
        "\n",
        "    train_inputs = inputs[:train_length]\n",
        "    train_labels = labels[:train_length]\n",
        "    validation_inputs = inputs[train_length:]\n",
        "    validation_labels = labels[train_length:]\n",
        "\n",
        "    accuracy_matrix = np.empty((possible_values_for_n.shape[0],train_length))\n",
        "\n",
        "    for n_id, n in enumerate(possible_values_for_n):\n",
        "      for k_id, k in enumerate(range(1,train_length+1)):\n",
        "        predicted_labels = majority_based_knn(train_inputs, train_labels,validation_inputs, n, k)\n",
        "        accuracy = calculate_accuracy(predicted_labels, validation_labels)\n",
        "        accuracy_matrix[n_id][k_id] = accuracy\n",
        "\n",
        "    max_acc = np.max(accuracy_matrix)\n",
        "    ties = (accuracy_matrix == max_acc)\n",
        "\n",
        "    n_id = np.argmax(np.any(ties,axis=1))\n",
        "    n = possible_values_for_n[n_id]\n",
        "    k = np.argmax(ties[n_id, :]) + 1\n",
        "\n",
        "    return np.array([k,n], dtype=int)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33ht_ji5iGlG"
      },
      "source": [
        "n_array = np.array([1, 2, 3, 4])\n",
        "get_best_k_n_values_using_validation_set(MNIST_X, MNIST_Y,20,n_array)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}